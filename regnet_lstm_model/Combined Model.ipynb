{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this Notebook as Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reynardo/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "from models.popular_models import PopularModels\n",
    "from models.lstm import LSTM\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from data.dataset import MultiLabelDataset\n",
    "from tools.tools import get_data, load_data, tokenize, remove_class, count_class, calculate_pos_weights\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR=\"../dataset/\" # the file containing the \"data\" folder and .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train_data = get_data(f\"{DIR}/train.csv\")\n",
    "test_data = get_data(f\"{DIR}/test.csv\")\n",
    "\n",
    "# perform text cleaning and get the pandas' dataframe\n",
    "train_data = load_data(train_data)\n",
    "test_data = load_data(test_data, has_label=False)\n",
    "\n",
    "# remove an imbalanced class\n",
    "train_data = remove_class(train_data, class_no=1)\n",
    "\n",
    "# split into training and validating sets\n",
    "X = train_data.iloc[:, 0:2]\n",
    "y = train_data.iloc[:, 2:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "val_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# join the data together\n",
    "for_nlp_data = pd.concat((train_data['caption'], val_data['caption'], test_data['caption']), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12740, 21)\n",
      "(3185, 21)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances: \t12740\n",
      "Number of validation instances: 3185\n",
      "Number of testing instances:  \t10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training instances: \t{train_data.shape[0]}\")\n",
    "print(f\"Number of validation instances: {val_data.shape[0]}\")\n",
    "print(f\"Number of testing instances:  \t{test_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Images and Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence Length: 28\n",
      "(25925, 28)\n",
      "(12740, 28)\n",
      "(3185, 28)\n",
      "(10000, 28)\n"
     ]
    }
   ],
   "source": [
    "# define the image transformation: currently following resnet18\n",
    "transform = transforms.Compose([\n",
    "\ttransforms.Resize((232, 232)),\n",
    "\ttransforms.CenterCrop(224),\n",
    "\ttransforms.ToTensor(), # converts images to [0, 1]\n",
    "\ttransforms.Normalize(\n",
    "\t\tmean=[0.485, 0.456, 0.406],\n",
    "\t\tstd=[0.229, 0.224, 0.225],\n",
    "\t)\n",
    "])\n",
    "\n",
    "# tokenize the data\n",
    "final_list, vocab = tokenize(for_nlp_data)\n",
    "X_train_vec = final_list[:train_data.shape[0], :]\n",
    "X_val_vec = final_list[train_data.shape[0]:train_data.shape[0]+val_data.shape[0], :]\n",
    "X_test_vec = final_list[train_data.shape[0]+val_data.shape[0]:, :]\n",
    "\n",
    "print(final_list.shape)\n",
    "print(X_train_vec.shape)\n",
    "print(X_val_vec.shape)\n",
    "print(X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dataset\n",
    "train_dataset = MultiLabelDataset(\n",
    "\tcsv_file=train_data,\n",
    "\troot_dir='../dataset/data/',\n",
    "\tvectorizer=None,\n",
    "\ttransform=transform,\n",
    "\tuse_caption_vec=True,\n",
    "\tcaption_vec=X_train_vec,\n",
    "\tis_test=False,\n",
    ")\n",
    "val_dataset = MultiLabelDataset(\n",
    "    csv_file=val_data,\n",
    "    root_dir='../dataset/data/',\n",
    "    vectorizer=None,\n",
    "\ttransform=transform,\n",
    "\tuse_caption_vec=True,\n",
    "\tcaption_vec=X_val_vec,\n",
    "\tis_test=False,\n",
    ")\n",
    "test_dataset = MultiLabelDataset(\n",
    "\tcsv_file=test_data,\n",
    "\troot_dir='../dataset/data/',\n",
    "\tvectorizer=None,\n",
    "\ttransform=transform,\n",
    "\tuse_caption_vec=True,\n",
    "\tcaption_vec=X_test_vec,\n",
    "\tis_test=True,\n",
    ")\n",
    "\n",
    "BATCH_SIZE=16\n",
    "\n",
    "# load the dataset into batches \n",
    "train_dataloader = DataLoader(\n",
    "\tdataset=train_dataset,\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\tshuffle=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\tshuffle=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "\tdataset=test_dataset,\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\tshuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "\n",
    "\tdef __init__(\n",
    "\t\t\tself, \n",
    "\t\t\tchoice: str, \n",
    "\t\t\tpretrained: bool, \n",
    "\t\t\tfreeze: bool, \n",
    "\t\t\tcnn_n_out: int,\n",
    "\t\t\tno_layers: int,\n",
    "\t\t\tvocab_size: int,\n",
    "\t\t\tembedding_dim: int,\n",
    "\t\t\tlstm_hidden_dim: int,\n",
    "\t\t\tlstm_n_out: int,\n",
    "\t\t\tlstm_dropout: float = 0.5,\n",
    "\t\t\tfc_dropout: float = 0.5,\n",
    "\t\t) -> None:\n",
    "\t\tsuper(CombinedModel, self).__init__()\n",
    "\n",
    "\t\t# get the CNN model for image classification\n",
    "\t\tself.cnn_model = PopularModels(\n",
    "\t\t\tchoice=choice,\n",
    "\t\t\tpretrained=pretrained,\n",
    "\t\t\tfreeze=freeze,\n",
    "\t\t\tn_out=cnn_n_out,\n",
    "\t\t).get_model()\n",
    "\n",
    "\t\t# get the LSTM model for text classification\n",
    "\t\tself.lstm_model = LSTM(\n",
    "\t\t\tno_layers=no_layers,\n",
    "\t\t\tvocab_size=vocab_size + 1,\n",
    "\t\t\tembedding_dim=embedding_dim,\n",
    "\t\t\thidden_dim=lstm_hidden_dim,\n",
    "\t\t\toutput_dim=lstm_n_out,\n",
    "\t\t\tdropout=lstm_dropout,\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\t# create the final fully connected layer\n",
    "\t\tself.last_layer = nn.Linear(cnn_n_out + lstm_n_out, 19)\n",
    "\t\t\n",
    "\t\t# prevent overfitting\n",
    "\t\tself.dropout_layer = nn.Dropout(p=fc_dropout, inplace=True)\n",
    "\n",
    "\tdef forward(self, x, y, hidden):\n",
    "\t\tx = self.cnn_model(x)\n",
    "\t\ty, hidden = self.lstm_model(y, hidden)\n",
    "\t\t\n",
    "\t\toutput = torch.cat((x, y), dim=1)\n",
    "\t\toutput = self.dropout_layer(output)\n",
    "\t\toutput = self.last_layer(output)\n",
    "\n",
    "\t\treturn output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = list(count_class(train_data).values())\n",
    "pos_weights = calculate_pos_weights(class_counts, train_data)\n",
    "if torch.cuda.is_available():\n",
    "\tpos_weights = pos_weights.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "THRESHOLD = 0.7\n",
    "N_CLASSES = 19\n",
    "\n",
    "model = CombinedModel(\n",
    "\tchoice=\"regnet_x_1_6gf\",\n",
    "\tpretrained=True, \t\t# if pretrained is False, then freeze should also be False\n",
    "\tfreeze=True,\n",
    "\tcnn_n_out=256,\n",
    "\tno_layers=2,\n",
    "\tvocab_size=len(vocab), \t# already added by 1\n",
    "\tembedding_dim=64,\n",
    "\tlstm_hidden_dim=256,\n",
    "\tlstm_n_out=128,\n",
    "    lstm_dropout=0,\n",
    "\tfc_dropout=0,\n",
    ")\n",
    "model.load_state_dict(torch.load('../regnet_lstm_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n"
     ]
    }
   ],
   "source": [
    "# create a file for test submission\n",
    "f = open('../submission_combined.csv', \"w\")\n",
    "f.write(\"ImageID,Labels\\n\")\n",
    "\n",
    "# utilise GPU\n",
    "if torch.cuda.is_available():\n",
    "\tprint('using GPU')\n",
    "\tmodel = model.to('cuda')\n",
    "\n",
    "# initialize the hidden state\n",
    "hidden = model.lstm_model.init_hidden(batch_size=BATCH_SIZE)\n",
    "\n",
    "# idx = 0\n",
    "model.eval()\n",
    "for (image_names, images, captions) in test_dataloader:\n",
    "\n",
    "\t# creating new variables for the hidden state, otherwise\n",
    "\t# we'd backprop through the entire training history\n",
    "\thidden = tuple([each.data for each in hidden])\n",
    "\t\n",
    "\tif torch.cuda.is_available():\n",
    "\t\timages = images.to('cuda')\n",
    "\t\tcaptions = captions.to('cuda')\n",
    "\t\n",
    "\toutputs, _ = model(images, captions, hidden)\n",
    "\tpredicted = (F.sigmoid(outputs) > THRESHOLD).int()\n",
    "\n",
    "\t# NOTE: add 1 to the output of predicted!\n",
    "\t# write the output\n",
    "\tfor i, predicted_label in enumerate(predicted):\n",
    "\t\tlabel = (predicted_label == torch.max(predicted_label)).nonzero().flatten()\n",
    "\t\tlabel += 1\n",
    "\t\tlabel = label.tolist()\n",
    "\t\tlabel = \" \".join(str(x) for x in label)\n",
    "\n",
    "\t\tf.write(image_names[i].split(\"/\")[-1] + \",\" + str(label) +\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
