{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "This notebook is just to test stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from typing import List\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"\"\"I thought this was a wonderful way to spend time on a too hot summer, sitting in the air conditioned theaterand watching a light-hearted comedy.\n",
    "I thought it was proof tha Woody Allen is still fully in control of the style many of us have grown to love.\n",
    "This may not be the crown jewel of his career, but it was wittier than 'Devil Wears Prada' and more interesting than 'Superman' a great comedy to go see with friends.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'thought': 2, 'comedy': 2, 'wonderful': 1, 'way': 1, 'spend': 1, 'time': 1, 'hot': 1, 'summer': 1, 'sitting': 1, 'air': 1, 'conditioned': 1, 'theaterand': 1, 'watching': 1, 'lighthearted': 1, 'proof': 1, 'tha': 1, 'woody': 1, 'allen': 1, 'still': 1, 'fully': 1, 'control': 1, 'style': 1, 'many': 1, 'us': 1, 'grown': 1, 'love': 1, 'may': 1, 'crown': 1, 'jewel': 1, 'career': 1, 'wittier': 1, 'devil': 1, 'wears': 1, 'prada': 1, 'interesting': 1, 'superman': 1, 'great': 1, 'go': 1, 'see': 1, 'friends': 1})\n",
      "['thought', 'comedy', 'wonderful', 'way', 'spend', 'time', 'hot', 'summer', 'sitting', 'air', 'conditioned', 'theaterand', 'watching', 'lighthearted', 'proof', 'tha', 'woody', 'allen', 'still', 'fully', 'control', 'style', 'many', 'us', 'grown', 'love', 'may', 'crown', 'jewel', 'career', 'wittier', 'devil', 'wears', 'prada', 'interesting', 'superman', 'great', 'go', 'see', 'friends']\n",
      "{'thought': 1, 'comedy': 2, 'wonderful': 3, 'way': 4, 'spend': 5, 'time': 6, 'hot': 7, 'summer': 8, 'sitting': 9, 'air': 10, 'conditioned': 11, 'theaterand': 12, 'watching': 13, 'lighthearted': 14, 'proof': 15, 'tha': 16, 'woody': 17, 'allen': 18, 'still': 19, 'fully': 20, 'control': 21, 'style': 22, 'many': 23, 'us': 24, 'grown': 25, 'love': 26, 'may': 27, 'crown': 28, 'jewel': 29, 'career': 30, 'wittier': 31, 'devil': 32, 'wears': 33, 'prada': 34, 'interesting': 35, 'superman': 36, 'great': 37, 'go': 38, 'see': 39, 'friends': 40}\n",
      "[[ 0  0  1  3  4  5  6  7  8  9 10 11 12 13 14  2]\n",
      " [ 0  0  0  1 15 16 17 18 19 20 21 22 23 24 25 26]\n",
      " [ 0 27 28 29 30 31 32 33 34 35 36 37  2 38 39 40]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  2],\n",
       "       [ 0,  0,  0,  1, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
       "       [ 0, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,  2, 38, 39, 40]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_string(s: str) -> str:\n",
    "\t# remove all non-word characters (everything except numbers and letters)\n",
    "\ts = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "\t# replace all the runs of whitespaces with no space\n",
    "\ts = re.sub(r\"\\s+\", '', s)\n",
    "\t# replace digits with no space\n",
    "\ts = re.sub(r\"\\d\", '', s)\n",
    "\treturn s\n",
    "\n",
    "def padding(sentences: List[int], seq_len: int) -> np.ndarray:\n",
    "\n",
    "\t# create a np zeros of \n",
    "\tfeatures = np.zeros((len(sentences), seq_len), dtype=int)\n",
    "\tfor i, review in enumerate(sentences):\n",
    "\t\tif (len(review) != 0):\n",
    "\t\t\tfeatures[i, -len(review):] = np.array(review)[:seq_len]\n",
    "\n",
    "\treturn features\n",
    "\n",
    "def tokenize(x_train: List[str]) -> np.ndarray:\n",
    "\t\n",
    "\tword_list = []\n",
    "\t\n",
    "\t# stop_words' example: ['hers', 'than', 'then', 'isn', 'shan't', etc.]\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\t\n",
    "\t# iterate through each sentence\n",
    "\tfor sentence in x_train:\n",
    "\n",
    "\t\tif len(sentence.lower().split()) == 0:\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\t# iterate through each word\n",
    "\t\tfor word in sentence.lower().split():\n",
    "\n",
    "\t\t\t# clean the word\n",
    "\t\t\tword = preprocess_string(word)\n",
    "\n",
    "\t\t\t# if the words have not appeared in stop words -> add the word in the word list\n",
    "\t\t\tif word not in stop_words and word != '':\n",
    "\t\t\t\tword_list.append(word)\n",
    "\n",
    "\t# create a corpus of all the words\n",
    "\tcorpus = Counter(word_list)\n",
    "\tprint(corpus)\n",
    "\t\n",
    "\t# sort on the basis of most common words\n",
    "\tcorpus_ = sorted(corpus, key=corpus.get, reverse=True)\n",
    "\tprint(corpus_)\n",
    "\n",
    "\t# creating a dict - this acts as a vocabulary\n",
    "\tonehot_dict = {w: i+1 for i,w in enumerate(corpus_)}\n",
    "\tprint(onehot_dict)\n",
    "\n",
    "\t# tokenize\n",
    "\tfinal_list_train = []\n",
    "\t# iterate through each sentence\n",
    "\tfor sentence in x_train:\n",
    "\n",
    "\t\tif len(sentence.lower().split()) == 0:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tls = []\n",
    "\n",
    "\t\t# iterate through each word\n",
    "\t\tfor word in sentence.lower().split():\n",
    "\n",
    "\t\t\t# clean the word\n",
    "\t\t\tword = preprocess_string(word)\n",
    "\n",
    "\t\t\t# word exists in vocabulary\n",
    "\t\t\tif (word in onehot_dict.keys()):\n",
    "\n",
    "\t\t\t\t# get the index based on the vocabulary\n",
    "\t\t\t\tidx = onehot_dict[word]\n",
    "\n",
    "\t\t\t\t# append the index to ls\n",
    "\t\t\t\tls.append(idx)\n",
    "\n",
    "\t\t# append the ls to the final list\n",
    "\t\tfinal_list_train.append(ls)\n",
    "\t\n",
    "\t# display\n",
    "\t# for list_train in final_list_train:\n",
    "\t# \tprint(list_train)\n",
    "\n",
    "\t# pad\n",
    "\tfinal_list_train = padding(final_list_train, 16)\n",
    "\tprint(final_list_train)\n",
    "\n",
    "\treturn final_list_train\n",
    "\n",
    "tokenize(example.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7, 5])\n",
      "tensor([[[4.0000, 3.6667, 6.0000, 4.3333, 8.0000],\n",
      "         [3.0000, 2.2500, 2.0000, 6.7500, 2.7500]],\n",
      "\n",
      "        [[4.6667, 5.6667, 3.3333, 5.0000, 3.3333],\n",
      "         [3.5000, 3.7500, 5.0000, 2.2500, 5.2500]],\n",
      "\n",
      "        [[6.6667, 5.6667, 4.6667, 0.6667, 6.3333],\n",
      "         [7.2500, 2.0000, 5.2500, 2.7500, 4.5000]]])\n",
      "tensor([[3.4286, 2.8571, 3.7143, 5.7143, 5.0000],\n",
      "        [4.0000, 4.5714, 4.2857, 3.4286, 4.4286],\n",
      "        [7.0000, 3.5714, 5.0000, 1.8571, 5.2857]])\n"
     ]
    }
   ],
   "source": [
    "# no layers = 3\n",
    "# batch size = 7\n",
    "# no of features = 5\n",
    "test = torch.randint(low=0, high=10, size=((3, 7, 5)))\n",
    "# print(test)\n",
    "print(test.shape)\n",
    "\n",
    "# we want to reduce to (3, 2, 5) by averaging each feature across the batch size\n",
    "target = 2\n",
    "\n",
    "no_layers = test.shape[0]\n",
    "current_batch_size = test.shape[1]\n",
    "no_features = test.shape[2]\n",
    "\n",
    "new_test = torch.zeros((no_layers, target, no_features))\n",
    "for i in range(no_layers):\n",
    "    \n",
    "\tn = current_batch_size // target\n",
    "\tfor j in range(target):\n",
    "\n",
    "\t\tt = test[i, n*j:n*(j+1), :].float()\n",
    "\t\tif (j == target - 1):\n",
    "\t\t\tt = test[i, n*j:, :].float()\n",
    "\t\t\n",
    "\t\tmean_t = torch.mean(t, dim=0)\n",
    "\t\tnew_test[i][j] = mean_t\n",
    "\n",
    "print(new_test)\n",
    "\n",
    "# below method does not work\n",
    "test = test.float()\n",
    "test = torch.mean(test, dim=1)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['class 1', 'class 2', 'class 3']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.zeros((10,3))\n",
    "if (torch.cuda.is_available()):\n",
    "    test = test.to('cuda')\n",
    "test = test.cpu().numpy()\n",
    "\n",
    "print(test.shape)\n",
    "\n",
    "test1 = np.ones((5,3))\n",
    "print(test1)\n",
    "\n",
    "test[0:5, :] = test1\n",
    "print(test)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'images': ['1.jpg', '2.jpg'],\n",
    "    'captions': ['lol', 'yea'],\n",
    "    'class 1': [1, 0],\n",
    "    'class 2': [1, 1],\n",
    "    'class 3': [0, 1],\n",
    "})\n",
    "df.columns[2:].to_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
