{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import ResNet18_Weights, MobileNet_V3_Large_Weights, EfficientNet_B2_Weights\n",
    "from dataset import MultiLabelDataset\n",
    "from tqdm import tqdm\n",
    "from tools import get_data, load_data, remove_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Text Cleaning & Data Extraction (Possibly for NLP)\n",
    "\n",
    "We will see how to code and clean the textual data for the following methods.\n",
    "- Lowecasing the data\n",
    "- Removing Puncuatations\n",
    "- Removing Numbers\n",
    "- Removing extra space\n",
    "- Replacing the repetitions of punctations\n",
    "- Removing Emojis\n",
    "- Removing emoticons\n",
    "- Removing Contractions\n",
    "Reference: https://www.analyticsvidhya.com/blog/2022/01/text-cleaning-methods-in-nlp/\n",
    "\n",
    "Manual Data Cleaning:\n",
    "- Remove `\\n` character that breaks the caption into two lines (1014.jpg)\n",
    "- Remove `\\n` character that breaks the caption into two lines (2259.jpg)\n",
    "- Remove `\\n` character that breaks the caption into two lines (6751.jpg)\n",
    "- Remove **a couple of** `\\n` character that breaks the caption into two lines (24624.jpg)\n",
    "\n",
    "**Note: there is no label 12! [Label starts from 1 to 19]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Labels\n",
    "\n",
    "There are 19 classes: class starts from 1 to 19. There is no label 12 assigned to any image. <br>\n",
    "For one-hot encoding: the 0-the index will represent class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train_data = get_data(\"./dataset/train.csv\")\n",
    "test_data = get_data(\"./dataset/test.csv\")\n",
    "\n",
    "# perform text cleaning and get the pandas' dataframe\n",
    "train_data = load_data(train_data)\n",
    "test_data = load_data(test_data, has_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances: 30000\n",
      "Number of testing instances:  10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training instances: {train_data.shape[0]}\")\n",
    "print(f\"Number of testing instances:  {test_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove instances with only class 1 (Data Imbalance Problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances: 15925\n"
     ]
    }
   ],
   "source": [
    "# remove an imbalanced class\n",
    "train_data = remove_class(train_data, class_no=1)\n",
    "print(f\"Number of training instances: {train_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Images and Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the image transformation: currently following resnet18\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((288, 288)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(), # converts images to [0, 1]\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dataset\n",
    "train_dataset = MultiLabelDataset(\n",
    "    csv_file=train_data,\n",
    "    root_dir='./dataset/data/',\n",
    "    vectorizer=None,\n",
    "    transform=transform,\n",
    ")\n",
    "test_dataset = MultiLabelDataset(\n",
    "    csv_file=test_data,\n",
    "    root_dir='./dataset/data/',\n",
    "    vectorizer=None,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "BATCH_SIZE=16\n",
    "\n",
    "# load the dataset into batches \n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model, Optimizer, Loss Function, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n"
     ]
    }
   ],
   "source": [
    "# model = models.mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V2)\n",
    "# model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model = models.efficientnet_b2(weights=EfficientNet_B2_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# freeze the top layers of the model\n",
    "for name, params in model.named_parameters():\n",
    "\n",
    "    # MobileNet V3\n",
    "    # if (\"classifier\" not in name):\n",
    "    #     params.requires_grad = False\n",
    "\n",
    "    # ResNet18\n",
    "    # if (\"fc\" not in name):\n",
    "    #     params.requires_grad = False\n",
    "\n",
    "    # EfficentNet B2\n",
    "    if (\"classifier\" not in name):\n",
    "        params.requires_grad = False\n",
    "\n",
    "# define the classifier layer again\n",
    "n_out = 19\n",
    "\n",
    "# MobileNet V3\n",
    "# model.classifier = nn.Sequential(\n",
    "#     nn.Linear(960, 1280),\n",
    "#     nn.Hardswish(inplace=True),\n",
    "#     nn.Dropout(p=0.2, inplace=True),\n",
    "#     nn.Linear(1280, n_out),\n",
    "# )\n",
    "\n",
    "# ResNet18\n",
    "# n_features = model.fc.in_features\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(in_features=n_features, out_features=n_out),\n",
    "# )\n",
    "\n",
    "# EfficientNet B2\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.3, inplace=True),\n",
    "    nn.Linear(in_features=1408, out_features=n_out),\n",
    ")\n",
    "\n",
    "# define hyperparameters\n",
    "EPOCHS = 5\n",
    "THRESHOLD = 0.5\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=0.01,\n",
    ")\n",
    "\n",
    "# utilise GPU\n",
    "if torch.cuda.is_available():\n",
    "    print('using GPU')\n",
    "    model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   0%|          | 0/996 [00:00<?, ?it/s]/home/reynardo/USYD/COMP4329/ASSIGNMENT 2/my_code/dataset.py:49: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  labels = torch.Tensor(self.df.iloc[idx, 2:])\n",
      "Epoch 1 Training: 100%|██████████| 996/996 [01:06<00:00, 15.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 12.9891046, Train Accuracy: 7.359%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 996/996 [01:06<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 22.4438925, Train Accuracy: 11.661%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 996/996 [01:06<00:00, 15.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 25.4430100, Train Accuracy: 11.906%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 996/996 [01:06<00:00, 15.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 28.7335936, Train Accuracy: 12.100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 996/996 [01:06<00:00, 15.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 30.5462551, Train Accuracy: 12.873%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_accs = []\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "\tn_total = 0\n",
    "\tn_correct = 0\n",
    "\ttrain_loss = 0.\n",
    "\tmodel.train()\n",
    "\tfor _, images, _, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1} Training: \"):\n",
    "\n",
    "\t\tif torch.cuda.is_available():\n",
    "\t\t\timages = images.to('cuda')\n",
    "\t\t\tlabels = labels.to('cuda')\n",
    "\n",
    "\t\ty_pred = model(images)\n",
    "\n",
    "\t\t# backward\n",
    "\t\tloss = loss_fn(y_pred, labels)\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\t# update\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\t# compare\n",
    "\t\tpredicted = (y_pred > THRESHOLD).int()\n",
    "\n",
    "\t\ttrain_loss += loss.item()\n",
    "\t\tn_correct += torch.all(torch.eq(predicted, labels), dim=1).sum()\n",
    "\t\tn_total += labels.shape[0]\n",
    "\n",
    "\ttrain_losses.append(train_loss / len(train_dataloader))\n",
    "\ttrain_accs.append(n_correct / n_total)\n",
    "\n",
    "\tprint(\"Epoch {:d}, Train Loss: {:.7f}, Train Accuracy: {:.3f}%\".format(epoch+1, train_losses[-1], train_accs[-1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Label Image Classification\n",
    "\n",
    "Tutorials:\n",
    "- [Build First Multi-Label Image Classification Model Python](https://www.analyticsvidhya.com/blog/2019/04/build-first-multi-label-image-classification-model-python/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
