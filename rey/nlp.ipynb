{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing the NLP side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tools import get_data, load_data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train_data = get_data(\"./dataset/train.csv\")\n",
    "test_data = get_data(\"./dataset/test.csv\")\n",
    "\n",
    "# perform text cleaning and get the pandas' dataframe\n",
    "train_data = load_data(train_data)\n",
    "test_data = load_data(test_data, has_label=False)\n",
    "\n",
    "# join the data together\n",
    "for_nlp_data = pd.concat((train_data['caption'], test_data['caption']), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          woman in swim suit holding parasol on sunny day\n",
       "1        a couple of men riding horses on top of a gree...\n",
       "2        they are brave for riding in the jungle on tho...\n",
       "3        a black and silver clock tower at an intersect...\n",
       "4          a train coming to a stop on the tracks out side\n",
       "                               ...                        \n",
       "29995    a picture of a truck that is in the middle of ...\n",
       "29996    a plate topped with a pizza being cut with a s...\n",
       "29997              a man riding a snowboard on top of snow\n",
       "29998      this photo shows people skiing in the mountains\n",
       "29999    two young men playing soccer and fighting for ...\n",
       "Name: caption, Length: 30000, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['caption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       a little girl waring a krispy kreme hat holdin...\n",
       "1       a beautiful young woman holding an orange frisbee\n",
       "2       a group of people sitting on couch next to a c...\n",
       "3               a person on a snowboard rides on the hill\n",
       "4       a man riding a skateboard with a helmet on in ...\n",
       "                              ...                        \n",
       "9995    a group of men riding surfboards riding a mass...\n",
       "9996    a motorcycle parked next to a car in a parking...\n",
       "9997              a little boy that is playing with a wii\n",
       "9998    group of kids play frisbee golf in the middle ...\n",
       "9999      a man in a gray jacket standing next to a woman\n",
       "Name: caption, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['caption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(sentence) for sentence in train_data['caption'].to_list()]\n",
    "print(max(lengths))\n",
    "\n",
    "lengths = [len(sentence) for sentence in test_data['caption'].to_list()]\n",
    "print(max(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True)\n",
    "vectorizer.fit(for_nlp_data)\n",
    "\n",
    "X_train_vec = vectorizer.transform(train_data['caption'])\n",
    "X_test_vec = vectorizer.transform(test_data['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 8075)\n",
      "(10000, 8075)\n"
     ]
    }
   ],
   "source": [
    "# the size of vocabulary is 8075\n",
    "print(X_train_vec.shape)\n",
    "print(X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train_vec.todense()).int()\n",
    "X_test_tensor = torch.from_numpy(X_test_vec.todense()).int()\n",
    "y_train_tensor = torch.from_numpy(np.array(train_data.iloc[:, 2:]))\n",
    "y_test_tensor = torch.from_numpy(np.array(test_data.iloc[:, 2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data, \n",
    "    batch_size=16, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_LSTM(nn.Module):\n",
    "    \n",
    "\tdef __init__(self, num_embeddings: int, embedding_dim: int, hidden_size: int, output_size: int) -> None:\n",
    "\t\tsuper(RNN_LSTM, self).__init__()\n",
    "\n",
    "\t\t# Add the word embedding layer\n",
    "\t\tself.embedding_layer = nn.Embedding(num_embeddings=num_embeddings+1, embedding_dim=embedding_dim)\n",
    "\n",
    "\t\t# Add the LSTM Layer\n",
    "\t\tself.lstm_layer = nn.LSTM(input_size=embedding_dim*num_embeddings, hidden_size=hidden_size)\n",
    "\n",
    "\t\t# Add the Output Layer\n",
    "\t\tself.fc_layer1 = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\tembeds = self.embedding_layer(x)\n",
    "\t\tlstm_out, _ = self.lstm_layer(embeds.view(len(x), -1))\n",
    "\t\ttag_space = self.fc_layer1(lstm_out)\t\t\n",
    "\t\ttag_scores = F.tanh(tag_space)\n",
    "\t\treturn tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "threshold = 0.5\n",
    "\n",
    "model = RNN_LSTM(\n",
    "    num_embeddings=8075,\n",
    "    embedding_dim=3,\n",
    "    hidden_size=1000,\n",
    "    output_size=19,\n",
    ")\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=0.01,\n",
    ")\n",
    "\n",
    "# utilise GPU\n",
    "if torch.cuda.is_available():\n",
    "    print('using GPU')\n",
    "    model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 1875/1875 [02:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.3677232, Train Accuracy: 46.897%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 1875/1875 [01:59<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.3675495, Train Accuracy: 46.917%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 1875/1875 [01:59<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.3675495, Train Accuracy: 46.917%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 1875/1875 [01:59<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.3675495, Train Accuracy: 46.917%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 1875/1875 [01:59<00:00, 15.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.3675495, Train Accuracy: 46.917%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_accs = []\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\tn_total = 0\n",
    "\tn_correct = 0\n",
    "\ttrain_loss = 0.\n",
    "\tmodel.train()\n",
    "\tfor captions, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training: \"):\n",
    "\n",
    "\t\tif torch.cuda.is_available():\n",
    "\t\t\tcaptions = captions.to('cuda')\n",
    "\t\t\tlabels = labels.to('cuda')\n",
    "\n",
    "\t\ty_pred = model(captions)\n",
    "\n",
    "\t\t# backward\n",
    "\t\tloss = loss_fn(y_pred, labels)\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\t# update\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\t# compare\n",
    "\t\tpredicted = (y_pred > threshold).int()\n",
    "\n",
    "\t\ttrain_loss += loss.item()\n",
    "\t\tn_correct += torch.all(torch.eq(predicted, labels), dim=1).sum()\n",
    "\t\tn_total += labels.shape[0]\n",
    "\n",
    "\ttrain_losses.append(train_loss / len(train_loader))\n",
    "\ttrain_accs.append(n_correct / n_total)\n",
    "\n",
    "\tprint(\"Epoch {:d}, Train Loss: {:.7f}, Train Accuracy: {:.3f}%\".format(epoch+1, train_losses[-1], train_accs[-1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
